{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Name: AG xx.\n",
    "\n",
    "Student Name (Student ID):\n",
    "\n",
    "1. Wong Ji Fong (A0249572U)\n",
    "\n",
    "2. xxxx xxxxx (xxxxxxx)\n",
    "\n",
    "3. xxxx xxxxx (xxxxxxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type hinting is used within this document to help understand parameters\n",
    "# Required, type hints refer to self:\n",
    "from __future__ import annotations\n",
    "# Assistive imports\n",
    "from collections import namedtuple\n",
    "from typing import Tuple, List, Optional, Set, Union, Generator\n",
    "from heapq import heappush"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Consider the maze shown below. The Maze has 16 rows and 24 columns The objective is to find a shortest path from cell $S$ to cell $G$.\n",
    "\n",
    "\n",
    "![Maze](Maze_Assignment_1-1.jpg)\n",
    "\n",
    "\n",
    "The agent can take four actions in each cell: 'RIGHT', 'DOWN', 'UP', 'LEFT'.  \n",
    "\n",
    "Each cell is represented as $(x,y)$, where $x$ indicates row number and $y$ indicates column number. Action 'UP' takes the agent from cell $(x,y)$ to $(x+1,y)$. Action 'DOWN' takes the agent from cell $(x,y)$ to $(x-1,y)$. Action 'RIGHT' takes the agent from cell $(x,y)$ to $(x,y+1)$. Action 'LEFT' takes the agent from cell $(x,y)$ to $(x,y-1)$. The triplet $(s,a,s')$  indicates that taking action $a$ at state $s$ leads to state $s'$. Actions 'LEFT' or 'RIGHT' cost 10 units for all $(s,a,s')$. Actions 'UP' or 'DOWN' cost 1 unit for all  $(s,a,s')$.  The agent cannot move into cells that are shaded. Assume that the agent knows the boundaries of the maze and has full observability. Consequently, at the bottom (row 0) and top (row 15), the agent will not take actions 'DOWN' and 'UP', respectively; at left (column 0) and right (column 23) columns, the agent will not take 'LEFT' and 'RIGHT' actions, respectively. Similalry, the agent will not take actions that lead to shaded region in the maze.\n",
    "\n",
    "## **Q1.a: Class Maze(Problem)** [3 Marks]\n",
    "\n",
    "Write a Maze class to create a model for this problem. You should not use an explicit state space model. The modelling should inherit the abstract class 'Problem' (given below). With the problem formulation, find the shortest path from S to G cell. Propose and implement multiple heuristics (at least two heuristics) for informed search algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q1.b: Analysis of the Algorithms** [7 Marks]\n",
    "\n",
    "1. Solve the above Maze problem using the following algorithms\n",
    "\n",
    "    a. Breadth-First Search \n",
    "\n",
    "    b. Depth-First Search with Cycle-Check\n",
    "\n",
    "    c. Iterative-Deepening Search with Cycle-Check\n",
    "\n",
    "    d. Uniform-Cost Search\n",
    "\n",
    "    e. A* Search \n",
    "\n",
    "    f. Greedy Best-first Search\n",
    "\n",
    "    g. Any other variants for search algorithms that are not discussed in the class (bonus/optional question) \n",
    "\n",
    "2. Identify the number of nodes generated, number of nodes expanded, maximum frontier size, and path-cost for the above algorithms. \n",
    " \n",
    "3. Compare the performance of informed search algorithms with proposed heuristics. Identify the best performing heuristic and explain.\n",
    " \n",
    "4. Draw a bar plot comparing the statistics of the algorithms and explain the results. \n",
    "\n",
    "Note 1: You must follow the problem formulation discussed in the class. A abstract class for Problem amd Node definition is presented below. The search tree generation should follow the template discussed in the class (i.e., Node class, expand methods, etc.). \n",
    "\n",
    "Note 2: If you are borrowing a block of code (for example, helper functions or data structures, etc.) from AIMA4e repository, you have to acknowledge it in the code. \n",
    "\n",
    "Note 3: The code should be written in a single jupyter notebook file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Problem:\n",
    "    \"\"\"The abstract class for a formal problem. A new domain subclasses this,\n",
    "    overriding `actions` and `results`, and perhaps other methods.\n",
    "    The default heuristic is 0 and the default action cost is 1 for all states.\n",
    "    When you create an instance of a subclass, specify `initial`, and `goal` states \n",
    "    (or give an `is_goal` method) and perhaps other keyword args for the subclass.\"\"\"\n",
    "\n",
    "    def __init__(self, initial=None, goal=None, **kwds): \n",
    "        self.__dict__.update(initial=initial, goal=goal, **kwds) \n",
    "        \n",
    "    def actions(self, state):        raise NotImplementedError\n",
    "    def result(self, state, action): raise NotImplementedError\n",
    "    def is_goal(self, state):        return state == self.goal\n",
    "    def action_cost(self, s, a, s1): return 1\n",
    "    def h(self, node):               return 0\n",
    "    \n",
    "    def __str__(self):\n",
    "        return '{}({!r}, {!r})'.format(\n",
    "            type(self).__name__, self.initial, self.goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following Node class to generate search tree\n",
    "import math\n",
    "# Defining a named tuple called state for readability\n",
    "# immutability and ephemeral use:\n",
    "NewState = namedtuple('NewState', ['cost', 'coordinates', 'action'])\n",
    "\n",
    "class Node:\n",
    "    \"A Node in a search tree.\"\n",
    "    def __init__(self, state, parent=None, action=None, path_cost=0):\n",
    "        self.__dict__.update(state=state, parent=parent, action=action, path_cost=path_cost)\n",
    "\n",
    "    \n",
    "    def __len__(self): return 0 if self.parent is None else (1 + len(self.parent))\n",
    "    def __lt__(self, other): return self.path_cost < other.path_cost \n",
    "    \n",
    "    # newly defined to assist with trace, and repr redefined\n",
    "    # for readability\n",
    "    def __repr__(self): \n",
    "        return '<state:(x:{},y:{}) path_cost:{} action:{}>'\\\n",
    "                .format(self.state[0], self.state[1], self.path_cost, self.action)\n",
    "    def __eq__(self, other: Node): return self.state == other.state\n",
    "    \n",
    "    def expand_node(self, state: NewState):\n",
    "        expanded_node = Node(state.coordinates)\n",
    "        expanded_node.parent = self\n",
    "        expanded_node.path_cost = self.path_cost + state.cost\n",
    "        expanded_node.action = state.action\n",
    "        return expanded_node\n",
    "    \n",
    "    def expand(self, permissable_actions: List[NewState]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            permissable_actions (List[NewState]):\n",
    "                List of possible actions to take\n",
    "        \"\"\"\n",
    "        return list(map(self.expand_node, permissable_actions))\n",
    "    \n",
    "    def __bool__(self):\n",
    "        return True if self.state else False\n",
    "    \n",
    "    def __hash__(self):\n",
    "        # for in set lookup for `visited`\n",
    "        return hash(self.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Maze(Problem):\n",
    "    def __init__(self,\n",
    "                 initial: Node,\n",
    "                 goal: Node,\n",
    "                 boundaries: Tuple[int, int],\n",
    "                 action_cost_map: Optional[dict],\n",
    "                 **kwds):\n",
    "        \"\"\"\n",
    "        Add type hints and parameter to know boundaries\n",
    "        given the assumption \"Assume that the agent knows\n",
    "        the boundaries of the maze and has full observability\"\n",
    "        \n",
    "        Args:\n",
    "            initial (Node): Node for the initial state\n",
    "            goal (Node): Node for the goal state\n",
    "            boundaries (Tuple[int,int]):\n",
    "                (rows, cols) of boundaries, assuming (0,0) to (rows,cols) \n",
    "                as problem space\n",
    "        \"\"\"\n",
    "        super().__init__(initial=initial,\n",
    "                         goal=goal,\n",
    "                         boundaries=boundaries,\n",
    "                         action_cost_map=action_cost_map,\n",
    "                         **kwds)\n",
    "    \n",
    "    def action_cost(self, node: Node, action: str) -> int:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            node (Node): Current node state\n",
    "            action (str): Action to take\n",
    "        \n",
    "        Returns:\n",
    "            int: Cost (s, a, s')\n",
    "        \"\"\"\n",
    "        return self.action_cost_map[action]\n",
    "    \n",
    "    def _transform_permissable_action(self,\n",
    "                                      actions: Tuple[Tuple[int, int], str],\n",
    "                                      node: Node) -> Node:\n",
    "        state, action = actions\n",
    "        action_cost = self.action_cost(node, action)\n",
    "        return NewState(action_cost, state, action)\n",
    "        \n",
    "    def actions(self, node: Node) -> List[Tuple[str, int]]:\n",
    "        \"\"\"\n",
    "        Return permissable actions as list of actions\n",
    "        as (COST, s', ACTION)\n",
    "        Args:\n",
    "            state (Node): Agents current state node\n",
    "        \n",
    "        Returns:\n",
    "            List[Node]:\n",
    "                List of permissable nodes\n",
    "        \"\"\"\n",
    "        x = node.state[0]\n",
    "        y = node.state[1]\n",
    "        parent = node.parent.state if node.parent else None\n",
    "        \n",
    "        permissable_x_y = {((x+1, y), 'UP'),\n",
    "                           ((x-1, y), 'DOWN'),\n",
    "                           ((x, y+1), 'RIGHT'),\n",
    "                           ((x, y-1), 'LEFT')}\n",
    "        \n",
    "        return list(\n",
    "                    map(\n",
    "                        lambda actions: self._transform_permissable_action(actions, node),\n",
    "                        filter(\n",
    "                                lambda actions:\n",
    "                                   # Ensuring they permissable actions are:\n",
    "                                   # * within boundaries\n",
    "                                   # * not parent, previous node\n",
    "                                   # * not a shaded region\n",
    "                                   0<=actions[0][0]<=self.boundaries[0] and\n",
    "                                   0<=actions[0][1]<=self.boundaries[1] and\n",
    "                                   (actions[0][0], actions[0][1]) != parent and\n",
    "                                   (actions[0][0], actions[0][1]) not in self.shaded_regions,\n",
    "                               permissable_x_y\n",
    "                        )\n",
    "                )\n",
    "           )\n",
    "    \n",
    "    def h(self, node: Node) -> Union[float, int]:\n",
    "        \"\"\"\n",
    "        Implementing Manhatten distance\n",
    "        Args:\n",
    "            node (Node): Current agent node\n",
    "        \n",
    "        Returns:\n",
    "            Union[float, int]: heuristic value\n",
    "        \"\"\"\n",
    "        return abs(self.goal.state[0]-node.state[0]) +\\\n",
    "                abs(self.goal.state[1]-node.state[1])\n",
    "    \n",
    "    def h2(self, node: Node) -> Union[float, int]:\n",
    "        \"\"\"\n",
    "        Implementing Euclidean distance\n",
    "        Args:\n",
    "            node (Node): Current agent node\n",
    "        \n",
    "        Returns:\n",
    "            Union[float, int]: heuristic value\n",
    "        \"\"\"\n",
    "        return ((self.goal.state[0]-node.state[0])**2 + \n",
    "                (self.goal.state[1]-node.state[1])**2)**(1/2)\n",
    "        \n",
    "        \n",
    "    def __repr__(self):\n",
    "        return '{}({!r}, {!r})'.format(\n",
    "            type(self).__name__, self.initial, self.goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating start and goal nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_node = Node((8,10))\n",
    "goal_node = Node((11,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<state:(x:8,y:10) path_cost:0 action:None>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating maze with start, end, maze size, boundaries, action costs and shaded regions (not known to agent itself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "maze = Maze(start_node,\n",
    "            goal_node,\n",
    "            boundaries=(15, 23),\n",
    "            action_cost_map={'LEFT':10, 'RIGHT': 10, 'UP': 1, 'DOWN': 1},\n",
    "            shaded_regions = {(7, 9),\n",
    "                              (6, 9),\n",
    "                              (10, 12),\n",
    "                              (10, 13),\n",
    "                              (11, 12),\n",
    "                              (10, 9),\n",
    "                              (12, 10),\n",
    "                              (9, 9),\n",
    "                              (13, 10),\n",
    "                              (8, 9),\n",
    "                              (11, 13),\n",
    "                              (10, 10),\n",
    "                              (14, 9),\n",
    "                              (11, 10)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example path to show permissable actions taking into account restrictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_1 = Node((0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NewState(cost=1, coordinates=(1, 0), action='UP'),\n",
       " NewState(cost=10, coordinates=(0, 1), action='RIGHT')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of permissable actions. From 0,0, agent can only move up and right.\n",
    "actions = maze.actions(node_1)\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<state:(x:1,y:0) path_cost:1 action:UP>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking the right\n",
    "expanded_node_1 = node_1.expand(actions)[0] # picking a child to then expand\n",
    "expanded_node_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NewState(cost=1, coordinates=(2, 0), action='UP'),\n",
       " NewState(cost=10, coordinates=(1, 1), action='RIGHT')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions_2 = maze.actions(expanded_node_1)\n",
    "actions_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_node_2 = expanded_node_1.expand(actions_2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<state:(x:2,y:0) path_cost:2 action:UP>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_node_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_all_actions_taken(state: Node) -> List[str]:\n",
    "    \"\"\"\n",
    "    Return path taken given node\n",
    "    Args:\n",
    "        state (Node): Node of a path\n",
    "    \n",
    "    Returns:\n",
    "        List[str]:\n",
    "            Actions taken in order from start\n",
    "    \"\"\"\n",
    "    all_actions = []\n",
    "    while state.action != None:\n",
    "        all_actions.append(state.action)\n",
    "        state = state.parent\n",
    "    return all_actions[::-1] # reverse it back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UP', 'UP']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_all_actions_taken(expanded_node_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NewState(cost=1, coordinates=(9, 11), action='DOWN'),\n",
       " NewState(cost=1, coordinates=(11, 11), action='UP')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of where agent will only be able to choose\n",
    "# up/down due to shaded areas\n",
    "maze.actions(Node((10,11)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per the comparison dunder method defined, comparing the nodes so far yields that node_2 has a higher pathcost than node_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_node_2 < expanded_node_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def bfs_search(maze: Maze):\n",
    "    initial_node = maze.initial\n",
    "    frontier = deque([initial_node])\n",
    "    visited = set()\n",
    "    while frontier:\n",
    "        frontier_node = frontier.popleft()\n",
    "        actions = maze.actions(frontier_node)\n",
    "        for child in frontier_node.expand(actions):\n",
    "            if child == maze.goal:\n",
    "                return child, visited\n",
    "            if child not in visited:\n",
    "                visited.add(child)\n",
    "                frontier.append(child)\n",
    "    return visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "child, visited = bfs_search(maze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes explored: 205\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nodes explored: {len(visited)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_state(draw_maze, \n",
    "               coord:Tuple[int, int],\n",
    "               marker_type:Literal['start', 'end', 'barrier', 'path', 'expand']):\n",
    "    mapping = {\n",
    "        'start': 10,\n",
    "        'end': 20,\n",
    "        'expand': 30,\n",
    "        'path': 40,\n",
    "        'barrier': 50,\n",
    "    }\n",
    "    draw_maze[-coord[0]][coord[1]] = mapping[marker_type]\n",
    "    return draw_maze\n",
    "\n",
    "def init_maze(maze):\n",
    "    cols = maze.boundaries[1]\n",
    "    rows = maze.boundaries[0]\n",
    "    draw_maze = [[0 for j in range(cols)] for i in range(rows)]\n",
    "    \n",
    "    draw_maze = plot_state(draw_maze, maze.initial.state, 'start')\n",
    "    draw_maze = plot_state(draw_maze, maze.goal.state, 'end')\n",
    "    \n",
    "    for barrier in maze.shaded_regions:\n",
    "        draw_maze = plot_state(draw_maze, barrier, 'barrier')\n",
    "    \n",
    "    return draw_maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "def bfs_search_animated(maze: Maze):\n",
    "    initial_node = maze.initial\n",
    "    frontier = deque([initial_node])\n",
    "    visited = set()\n",
    "    \n",
    "    expanded = []\n",
    "    while frontier:\n",
    "        frontier_node = frontier.popleft()\n",
    "        actions = maze.actions(frontier_node)\n",
    "        for child in frontier_node.expand(actions):\n",
    "            # for animation\n",
    "            expanded.append((child.state, 'expand'))\n",
    "            if child == maze.goal:\n",
    "                return child, visited, expanded\n",
    "            if child not in visited:\n",
    "                visited.add(child)\n",
    "                frontier.append(child)\n",
    "    return visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_all_states_taken(state: Node) -> List[str]:\n",
    "    \"\"\"\n",
    "    Return path taken given node\n",
    "    Args:\n",
    "        state (Node): Node of a path\n",
    "    \n",
    "    Returns:\n",
    "        List[str]:\n",
    "            Actions taken in order from start\n",
    "    \"\"\"\n",
    "    all_actions = []\n",
    "    while state.action != None:\n",
    "        all_actions.append((state.state, 'path'))\n",
    "        state = state.parent\n",
    "    return all_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution, visited, expanded = bfs_search_animated(maze)\n",
    "expanded.extend(trace_all_states_taken(solution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "def animate_algo(maze, \n",
    "                 expanded: List[Tuple[int,int], str], \n",
    "                 filename:str) -> str:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        expanded (List[Tuple[int,int], str):\n",
    "            List of coordinate pairs and markers to display\n",
    "        filename (str):\n",
    "            Filename to save the video file of the algo as\n",
    "    \n",
    "    Returns:\n",
    "        str: filename to play using IPython.display.Video\n",
    "    \"\"\"\n",
    "    maze_map = init_maze(maze)\n",
    "\n",
    "    def tick_range(n):\n",
    "        value = -0.5\n",
    "        arr = [value]\n",
    "        while value < n-1:\n",
    "            value += 1\n",
    "            arr.append(value)\n",
    "        return arr\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    cmap = colors.ListedColormap(\n",
    "            ['white','green', 'red', 'blue','green','black']\n",
    "    )\n",
    "    bounds = [0,10,20,30,40,50]\n",
    "    data = ax.imshow(maze_map, cmap=cmap, vmin=0, vmax=50)\n",
    "    ax.grid(which='major', axis='both', linestyle='-', color='k', linewidth=2)\n",
    "    rows=maze.boundaries[0]\n",
    "    cols=maze.boundaries[1]\n",
    "    ax.set_xticks(tick_range(cols))\n",
    "    ax.set_yticks(tick_range(rows))\n",
    "\n",
    "    def animate_func(i, maze_map):\n",
    "        maze_map = plot_state(maze_map,\n",
    "                              expanded[i][0],\n",
    "                              expanded[i][1])\n",
    "        data.set_data(maze_map)\n",
    "        return [data]\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, \n",
    "                                   animate_func,\n",
    "                                   frames=len(expanded),\n",
    "                                   interval=20,\n",
    "                                   fargs=(maze_map,),\n",
    "                                   repeat=False)\n",
    "    anim.save(filename, writer='ffmpeg') # to save\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"bfs.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Video(animate_algo(maze, expanded, 'bfs.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristics 1 and 2\n",
    "Defining an arbitrary node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_node = Node((9,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhatten distance: 3\n",
      "Euclidean distance: 2.23606797749979\n"
     ]
    }
   ],
   "source": [
    "print(f\"Manhatten distance: {maze.h(intermediate_node)}\")\n",
    "print(f\"Euclidean distance: {maze.h2(intermediate_node)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Tests, please ignore but use for testing classes\n",
    "print(start_node == Node((8,10)))\n",
    "print(goal_node == Node((11, 9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "85c6d5c81e07e5df96d46470b5f31cdc60bf99937c21eb8030f5ac9c2291ee2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
